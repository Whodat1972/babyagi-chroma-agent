import os
import openai
from dotenv import load_dotenv
from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
import langchain
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain import PromptTemplate, LLMChain
from collections import deque
from typing import Dict, List
from langchain.schema import HumanMessage, SystemMessage
from langchain.schema import Document, HumanMessage, SystemMessage



# Set Variables
load_dotenv()

# Set API Keys
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
assert OPENAI_API_KEY, "OPENAI_API_KEY environment variable is missing from .env"

# Table / Index / Collection config
YOUR_TABLE_NAME = os.getenv("TABLE_NAME", "")
assert YOUR_TABLE_NAME, "TABLE_NAME environment variable is missing from .env"

# Project config
OBJECTIVE = os.getenv("OBJECTIVE", "")
assert OBJECTIVE, "OBJECTIVE environment variable is missing from .env"

# This is the first task that the user will be asked to complete
YOUR_FIRST_TASK = os.getenv("FIRST_TASK", "")
assert YOUR_FIRST_TASK, "FIRST_TASK environment variable is missing from .env"

# Print OBJECTIVE
print("\033[96m\033[1m" + "\n*****OBJECTIVE*****\n" + "\033[0m\033[0m")
print(OBJECTIVE)

# Configure OpenAI
openai.api_key = OPENAI_API_KEY

# Assigning table_name to YOUR_TABLE_NAME
table_name = YOUR_TABLE_NAME

embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

# openai call: for the executing functions
llm = OpenAI()

persist_directory = 'database'
vectorstore = Chroma(table_name, embedding, persist_directory=persist_directory)
vectorstore.persist()

# # Get the collection, we use the same embedding function as the one used to create the index
collection = vectorstore._client.get_or_create_collection(name=table_name, embedding_function=embedding)

# Task list; deque is a double-ended queue, which is a list-like data structure that supports adding and removing elements from either end
task_list = deque([])

# add task to the task list
def add_task(task: Dict):
    task_list.append(task)

# uses model text-embedding-ada-002 by default
def get_ada_embedding(text):
    text = text.replace("\n", " ")
    embeddings = embedding.embed_query(text) 
    print("Text:", text)
    print("Embeddings:", embeddings)
    print("Embedding dimensions:", len(embeddings))
    print("First and Most Recent Embedding:", embeddings[0])
    return [embeddings]  # return a 2D array containing the single embedding
text = "This is a test query."
get_ada_embedding(text)

# openai call: for the future executing agent
def openai_call(text, use_gpt3=False):
    model_name = "text-davinci-003" if use_gpt3 else "gpt-4"
    openaichat = ChatOpenAI(model_name=model_name)
    # Pass one or more messages to the chat model
    messages = [
        SystemMessage(content="You are a helpful assistant."),
        HumanMessage(content=text)
    ]
    response = openaichat(messages)
    # The response will be an AIMessage object
    return response.content
text = "This is a test query."
print(openai_call(text))

# edit later 
def task_creation_agent(task_description: str, result: Dict, task_list: List[str], gpt_version: str = 'gpt-4'):
  create_task = PromptTemplate(
    input_variables=["objective", "result", "task_description", "task_list"],
    template="You are a task creation AI that uses the result of an execution agent to create new tasks with the following objective: {objective}. The last completed task has the result: {result}. This result was based on this task description: {task_description}. These are incomplete tasks: {task_list}. Based on the result, create new tasks to be completed by the AI system that do not overlap with incomplete tasks. Return the tasks as an array.",)
  response = openai_call(create_task.format(objective=OBJECTIVE, result=result, task_description=task_description, task_list=', '.join(task_list)))
  new_tasks = response.split('\n')
  print("New tasks:", new_tasks)
  # return [{"task_name": task_name} for task_name in new_tasks]
  return [{"task_id": None, "task_name": task_name} for task_name in new_tasks]

sample_result = "The test result."
sample_task_description = "This is a sample task description."
sample_task_list = ["Task 1", "Task 2", "Task 3"]
# Call the task_creation_agent() function with the sample inputs
new_tasks = task_creation_agent( sample_task_description, sample_result, sample_task_list)
# Print the new tasks generated by the function
print("New tasks:")
for task in new_tasks:
    print(task["task_name"])

def prioritization_agent(this_task_id:int, gpt_version: str = 'gpt-4'):
  global task_list
  task_names = [task['task_name'] for task in task_list]
  next_task_id = int(this_task_id)+1
  prioritize_task = PromptTemplate(
    input_variables=["task_names", "objective", "next_task_id"],
    template="You are a task prioritization AI tasked with cleaning the formatting of and reprioritizing the following tasks: {task_names}. Consider the ultimate objective of your team: {objective}. Do not remove any tasks. Return the result as a numbered list, like:\n#. First task\n#. Second task\nStart the task list with number {next_task_id}")
  response = openai_call(prioritize_task.format(objective=OBJECTIVE, task_names=task_names, next_task_id=next_task_id))
  new_tasks = response.split('\n')
  task_list = deque()
  for task_string in new_tasks:
    task_parts = task_string.strip().split(".", 1)
    if len(task_parts) == 2:
            task_id = task_parts[0].strip()
            task_name = task_parts[1].strip()
            task_list.append({"task_id": task_id, "task_name": task_name})
            
def context_agent(query: str, chroma: Chroma, n: int):
    query_embedding = get_ada_embedding(query)
    results = chroma.similarity_search_by_vector(query_embedding[0], k=n)
    print("Docs most similar to vector", results)
    # Return the page_content of each document
    return [str(result.page_content) for result in results]

text = "This is a test query."
resulting_tasks = context_agent(text, vectorstore, 5)
print(resulting_tasks)
            
def execution_agent(objective: str, task: str, chroma: Chroma, n: int):
    # Get context
    context = context_agent(query=task, chroma=vectorstore, n=n)
    # call the prompt
    execute_task = PromptTemplate(
        input_variables=["objective", "context", "task"],
        template="You are an AI who performs one task based on the following objective: {objective}.\nTake into account these previously completed tasks: {context}\nYour task: {task}\nResponse:"
    )
    response = openai_call(execute_task.format(objective=OBJECTIVE, context=', '.join(context), task=task))
    return response
# Test the execution_agent function
objective = "Find the best way to make a sandwich."
task = "List the ingredients for a delicious sandwich."
n = 5
response = execution_agent(objective=objective, task=task, chroma=vectorstore, n=n)
print("Execution agent response:", response)

# Add the first task to the task list
first_task = {
    "task_id": 1,
    "task_name": YOUR_FIRST_TASK
}

add_task(first_task)

# Main loop
task_id_counter = 1
while True:
    if task_list:
        # Print the task list
        print("\033[95m\033[1m" + "\n*****TASK LIST*****\n" + "\033[0m\033[0m")
        for t in task_list:
            print(str(t['task_id']) + ": " + t['task_name'])

        # Step 1: Pull the first task from the task list
        task = task_list.popleft()
        print("\033[92m\033[1m" + "\n*****NEXT TASK*****\n" + "\033[0m\033[0m")
        print(str(task['task_id']) + ": " + task['task_name'])

        # Step 2: Execute the task, completing based on the context
        result = execution_agent(objective=OBJECTIVE, task=task['task_name'], chroma=vectorstore, n=5)

        # Step 3: Enrich results and add to Chroma
        enriched_results = {'data': result}
        results_id = f"result_{task['task_id']}"
        vector = enriched_results["data"]
        # vectorstore.add_documents(results_id, vector, {"task": task['task_name'], "result": result})
        document = Document(page_id=results_id, page_content=vector, metadata={"task": task['task_name'], "result": result})
        vectorstore.add_documents([document])

    # Step 4: Create new tasks based on the result
    new_tasks = task_creation_agent(task_description=task['task_name'], result=result, task_list=[t['task_name'] for t in task_list])

    # Step 5: Update and Prioritize the new tasks
    for new_task in new_tasks:
        task_id_counter += 1
        new_task.update({"task_id": task_id_counter})
        add_task(new_task)
    prioritization_agent(this_task_id=task['task_id'], gpt_version='gpt-4')
    
#   todo: fix bugs, reformate code, add comments, add docstrings, add tests, add type hint
#   fully comprehend code
#   make it look prettier, show steps
#   make a commit, add description, add tags
  

    
# references:
# https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html
# https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/chroma.html?highlight=chroma%20embed
# https://python.langchain.com/en/latest/reference/modules/vectorstore.html?highlight=chroma#langchain.vectorstores.Chroma
# https://python.langchain.com/en/latest/_modules/langchain/vectorstores/chroma.html#Chroma.from_documents
# https://python.langchain.com/en/latest/modules/indexes/vectorstores/getting_started.html

